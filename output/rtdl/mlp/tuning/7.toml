program = 'bin/mlp.py'

[base_config]
seed = 7

    [base_config.data]
    normalization = 'standard'
    path = 'data/rtdl'
    y_policy = 'quantile_mean_std'

    [base_config.model]
    activation = 'relu'

    [base_config.training]
    batch_size = 1024
    eval_batch_size = 8192
    n_epochs = 1000000000
    optimizer = 'adamw'
    patience = 16
    loss = 'mse'

[optimization.options]
n_trials = 1500

[optimization.sampler]
seed = 7

[optimization.space.model]
d_layers = [ '$mlp_d_layers', 1, 6, 1, 1024 ]
dropout = [ '?uniform', 0.0, 0.0, 0.5 ]

[optimization.space.training]
lr = [ 'loguniform', 1e-05, 0.01 ]
weight_decay = [ '?loguniform', 0.0, 1e-06, 0.001 ]
